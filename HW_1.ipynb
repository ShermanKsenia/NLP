{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cf8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a35a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee5184",
   "metadata": {},
   "source": [
    "### 1. Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd67b6",
   "metadata": {},
   "source": [
    "Я выбрала сайт https://www.turpravda.com/tn/top-hotels.html с отзывами на отели Туниса. Оттуда я взяла страницы с отелями, которые оценивались на 9-10, 7, 6 и 1-5 баллов в среднем. На каждой странице максимум 25 отелей. \n",
    "\n",
    "Так как страницы с самими отзывами позволяют просматривать новые отзывы только по нажатию специальной кнопки, пришлось брать только по 10 первых отзывов с каждой страницы, так как я не нашла функционала, с помощью которого можно достать больше отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b7bff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comments(page_url):\n",
    "    global df_comments\n",
    "    \n",
    "    session = requests.session()\n",
    "    req = session.get(page_url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    for comment in soup.find_all('div', {'class': 'ans_body'}):\n",
    "        mark = comment.find('span', {'class': 'value'})\n",
    "        if mark:\n",
    "            comment_text = comment.find('span', {'class': 'all-text'}).text\n",
    "            mark = float(mark.text[-4:])\n",
    "            df_comments = df_comments.append({'comment': comment_text, \n",
    "                                              'mark': mark,\n",
    "                                              'url': page_url}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "087f5306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:25<00:00,  1.58s/it]\n",
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n",
      "100%|██████████| 25/25 [01:24<00:00,  3.38s/it]\n",
      "100%|██████████| 25/25 [02:01<00:00,  4.85s/it]\n",
      "100%|██████████| 25/25 [00:48<00:00,  1.93s/it]\n",
      "100%|██████████| 21/21 [01:41<00:00,  4.85s/it]\n"
     ]
    }
   ],
   "source": [
    "df_comments = pd.DataFrame(columns=['comment', 'mark', 'url'])\n",
    "rates = [9, 7, 6, 5, '5&p=2', '5&p=3']\n",
    "\n",
    "for i in rates:\n",
    "    page_url = f'https://www.turpravda.com/tn/top-hotels.html?rte%5B%5D={i}'\n",
    "    session = requests.session()\n",
    "    req = session.get(page_url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    all_hrefs = soup.find_all('a', {'class': 'hotel-name-title'})\n",
    "    for href in tqdm(all_hrefs):\n",
    "        link = href.get('href')\n",
    "        get_comments('https://www.turpravda.com' + link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffca56c",
   "metadata": {},
   "source": [
    "Таким образом, у меня получилось почти равное количество положительных и отрицательных отзывов. К отрицательным я относила те отзывы, в которых оценка от 1 до 5, включительно. Остальные я относила к положительным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f60ee2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    491\n",
       "0    474\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments['sentiment'] = df_comments['mark'].apply(lambda x: 1 if x > 5 else 0)\n",
    "df_comments['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc14771",
   "metadata": {},
   "source": [
    "### 2. Создание словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3969075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pymorphy2.MorphAnalyzer()\n",
    "sw = stopwords.words('russian')\n",
    "def clean_text(text):\n",
    "    tokens = []\n",
    "    for word in word_tokenize(text):\n",
    "        if word.isalpha():\n",
    "            if word not in sw:\n",
    "                tokens.append(m.parse(word.lower())[0].normal_form)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39b4cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['tokens'] = df_comments['comment'].apply(clean_text)\n",
    "df_comments['clean_comment'] = df_comments['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7312217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_comments['tokens']\n",
    "y = df_comments['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b550b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = y==1\n",
    "positive_comments = X_train[mask_pos].tolist()\n",
    "negative_comments = X_train[~mask_pos].tolist()\n",
    "\n",
    "positive_corpus = []\n",
    "negative_corpus = []\n",
    "\n",
    "for t in positive_comments:\n",
    "    positive_corpus.extend(t)\n",
    "for t in negative_comments:\n",
    "    negative_corpus.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07acc74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only positive:\n",
      "{'турция', 'неплохой', 'белый', 'быстро', 'сахар', 'кухня', 'спасибо', 'отличный', 'внимание', 'интересный', 'английский', 'выбрать', 'такси', 'для', 'зелёный', 'улица', 'именно', 'центр', 'приятный', 'недостаток', 'хаммамет', 'прекрасный', 'разнообразный', 'шоу', 'уровень', 'уходить', 'бесплатно', 'французский', 'выбирать', 'замечательный', 'супер', 'горка', 'красивый', 'бесплатный', 'ребята', 'вкусно', 'вход', 'линия', 'приветливый', 'сусс', 'обязательно', 'медина', 'некоторый', 'целое', 'берег', 'тёплый', 'покупать', 'метр', 'довольный', 'до', 'вполне', 'чисто', 'качество', 'небольшой', 'язык', 'француз', 'минус', 'дешёвый', 'любой', 'поездка', 'порт', 'достаточно', 'купаться', 'отлично', 'семья', 'погода', 'новый', 'обслуживание', 'кормить', 'пройти'}\n",
      "Only negative:\n",
      "{'нечего', 'полный', 'шезлонг', 'тип', 'убираться', 'ванная', 'остальной', 'музыка', 'принцип', 'приходить', 'грязь', 'телевизор', 'к', 'стоять', 'кроме', 'рука', 'прийтись', 'вещь', 'принести', 'следующий', 'жить', 'плохо', 'должный', 'тарелка', 'столовая', 'муха', 'посуда', 'пока', 'автобус', 'бутылка', 'начать', 'количество', 'араб', 'получить', 'какой', 'причём', 'соседний', 'выходить', 'пить', 'ужасный', 'гость', 'дверь', 'кровать', 'оставить', 'стакан', 'занимать', 'отвратительный', 'что', 'туалет', 'бельё', 'просить', 'думать', 'дело', 'иметь', 'окно', 'матрас', 'либо', 'приходиться', 'после', 'прийти', 'единственный', 'грязный', 'алкоголь', 'туроператор', 'он', 'запах', 'столик', 'ужас', 'часто', 'спать'}\n"
     ]
    }
   ],
   "source": [
    "cnt_pos = Counter(positive_corpus).most_common(300)\n",
    "cnt_neg = Counter(negative_corpus).most_common(300)\n",
    "\n",
    "set_pos = set(dict(cnt_pos).keys())\n",
    "set_neg = set(dict(cnt_neg).keys())\n",
    "print('Only positive:')\n",
    "print(set_pos-set_neg)\n",
    "print('Only negative:')\n",
    "print(set_neg-set_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "286d7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_pos = set_pos - set_neg\n",
    "only_neg = set_neg - set_pos\n",
    "def sentiment(comments):\n",
    "    cnt_pos = 0\n",
    "    cnt_neg = 0\n",
    "    result = []\n",
    "    for i, comment in enumerate(comments):\n",
    "        for token in comment:\n",
    "            if token in only_pos:\n",
    "                cnt_pos += 1\n",
    "            elif token in only_neg:\n",
    "                cnt_neg += 1\n",
    "        if cnt_neg > cnt_pos:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "        cnt_pos = 0\n",
    "        cnt_neg = 0\n",
    "    return result\n",
    "\n",
    "y_pred = sentiment(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a0adc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875647668393783"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_count(y_pred, y_test):\n",
    "    cnt = 0\n",
    "    for p, t in zip(y_pred, y_test):\n",
    "        if p == t:\n",
    "            cnt += 1\n",
    "    return cnt / len(y_pred)\n",
    "\n",
    "accuracy_count(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74d104",
   "metadata": {},
   "source": [
    "Полученный способ позволил достичь accuracy ~0.788. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f506a",
   "metadata": {},
   "source": [
    "### Добавление моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5d7a3",
   "metadata": {},
   "source": [
    "С помощью словарей мы обращаем внимание на количество слов, принадлежащих одному или другому классу, однако, возможно важно смотреть не столько на количество всех слов одного класса, сколько на количество определённых слов по отдельности. Поэтому я предлагаю закодировать вектора с помощью CountVectorizer, чтобы обращать внимание на все слова в комментарии, и предсказывать с помощью Logistic Regression, который после обучения сможет поставить коэффициенты на те слова, которые наиболее сильно влияют на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76d4e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comments = df_comments['clean_comment']\n",
    "y_comments = df_comments['sentiment']\n",
    "X_comments_train, X_comments_test, y_comments_train, y_comments_test = train_test_split(X_comments, y_comments, train_size=.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55bdda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "X_train_vec = vec.fit_transform(X_comments_train)\n",
    "X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X_train_vec, y_comments_train)\n",
    "y_preds = clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d57ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341968911917098"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_count(y_preds, y_comments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426539b",
   "metadata": {},
   "source": [
    "Качество улучшилось на приблизительно на 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b464b0c",
   "metadata": {},
   "source": [
    "Более хороший результат получается при использовании баесовской модели MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78083cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8652849740932642"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_comments_train)\n",
    "y_preds = clf.predict(X_test_vec)\n",
    "accuracy_count(y_preds, y_comments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f29fbc",
   "metadata": {},
   "source": [
    "Также я решила попробовать обучить модель определять тональность комментария на основе эмбеддинга самого комментария. Для этого я взяла обученную модель Word2Vec, подстроила данные под входные данные для модели и каждый отзыв представила как средний вектор всех представлений слов. После я обучила модель Logistic Regression предсказывать тональность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af232f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 772/772 [00:31<00:00, 24.32it/s]\n",
      "100%|██████████| 193/193 [00:10<00:00, 18.73it/s]\n"
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-ruscorpora-300')\n",
    "\n",
    "# Перевод pos-тэгов pymorphy в pos-тэги модели (причастия и деепричастия я считала глаголами)\n",
    "pos_model = {'NOUN': 'NOUN', 'VERB': 'VERB', 'ADJF': 'ADJ', \n",
    "            'ADJS': 'ADJ', 'PRTS': 'VERB', 'COMP': 'ADJ',\n",
    "            'ADVB': 'ADV', 'INFN': 'VERB', 'NPRO': 'PRON', \n",
    "            'PREP':'ADP', 'PRED': 'ADV', 'PRTF': 'VERB',\n",
    "            'NUMR': 'NUM', 'CONJ': 'CCONJ', 'INTJ': 'INTJ', \n",
    "            'PRCL': 'PART', 'GRND': 'VERB'}\n",
    "\n",
    "# создание датасета для модели\n",
    "# к каждому слову в конце добавляется тэг части речи\n",
    "X_train_wv = []\n",
    "for comment in tqdm(X_train):\n",
    "    new_comment = []\n",
    "    for word in comment:\n",
    "        pos = m.parse(word)[0].tag.POS\n",
    "        if pos:\n",
    "            new_comment.append(f'{word}_{pos_model[pos]}')\n",
    "    X_train_wv.append(new_comment)\n",
    "\n",
    "X_test_wv = []\n",
    "for comment in tqdm(X_test):\n",
    "    new_comment = []\n",
    "    for word in comment:\n",
    "        pos = m.parse(word)[0].tag.POS\n",
    "        if pos:\n",
    "            new_comment.append(f'{word}_{pos_model[pos]}')\n",
    "    X_test_wv.append(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1f53bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "empts = []  # список слов, которых нет в словаре модели (с повторениями)\n",
    "all_words = 0  # счётчик общего количества слов (с повторениями)\n",
    "\n",
    "# создание вектора отзыва\n",
    "# случаи, когда ни одно слово не входило в словарь, исключались\n",
    "X_train_emb = []\n",
    "y_train_emb = []\n",
    "for comment, y in zip(X_train_wv, y_train):\n",
    "    comment_emb = []\n",
    "    all_words += len(comment)\n",
    "    for word in comment:\n",
    "        try:\n",
    "            comment_emb.append(model[word])\n",
    "        except:\n",
    "            empts.append(word)\n",
    "    if comment_emb != []:\n",
    "        X_train_emb.append(np.mean(comment_emb, axis=0))\n",
    "        y_train_emb.append(y)\n",
    "\n",
    "X_test_emb = []\n",
    "y_test_emb = []\n",
    "for comment, y in zip(X_test_wv, y_test):\n",
    "    comment_emb = []\n",
    "    all_words += len(comment)\n",
    "    for word in comment:\n",
    "        try:\n",
    "            comment_emb.append(model[word])\n",
    "        except:\n",
    "            empts.append(word)\n",
    "    if comment_emb != []:\n",
    "        X_test_emb.append(np.mean(comment_emb, axis=0))\n",
    "        y_test_emb.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa43bd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927461139896373"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X_train_emb, y_train_emb)\n",
    "y_preds = clf.predict(X_test_emb)\n",
    "accuracy_count(y_preds, y_test_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a710e3b",
   "metadata": {},
   "source": [
    "Таким образом, accuracy улучшилась, хоть и несильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f7a7a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова не из словаря: 42558\n",
      "Слова в словаре: 189202\n"
     ]
    }
   ],
   "source": [
    "print('Слова не из словаря:', len(empts))\n",
    "print('Слова в словаре:', all_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
