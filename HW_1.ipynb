{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cf8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a35a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6169bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [\n",
    "    'https://www.turpravda.com/tn/monastir/One_Resort_Aqua_Park___Spa-h47466.html',\n",
    "    'https://www.turpravda.com/tn/monastir/magic_caribbean_monastir-h17529.html#reviews',\n",
    "    'https://www.turpravda.com/tn/monastir/El_Mouradi_Skanes-h17330.html',\n",
    "    'https://www.turpravda.com/tn/monastir/Delphin_El_Habib_Resort-h23475.html',\n",
    "    'https://www.turpravda.com/tn/monastir/Liberty_Hotel-h12058.html',\n",
    "    'https://www.turpravda.com/tn/monastir/Jokey_Club_Palm_Garden-h11867.html',\n",
    "    'https://www.turpravda.com/tn/monastir/Le_Soleil_Bella_Vista_Resort_Hotel-h11735.html',\n",
    "    'https://www.turpravda.com/tn/monastir/Thalassa_Village_Skanes-h15773.html',\n",
    "    'https://www.turpravda.com/tn/monastir/palmyra_holiday_resort_spa-h12610.html',\n",
    "    'https://www.turpravda.com/tn/port_el_kantaui/lti_bellevue_park-h9490.html',\n",
    "    'https://www.turpravda.com/tn/mahdija/Iberostar_Royal_El_Mansour_Hotel-h25863.html',\n",
    "    'https://www.turpravda.com/tn/suss/Royal_Kenz_Hotel_Thalasso___Spa-h16856.html',\n",
    "    'https://www.turpravda.com/tn/hammamet/Club_President_Hotel-h33254.html',\n",
    "    'https://www.turpravda.com/tn/port_el_kantaui/El_Hana_Hannibal_Palace-h11766.html',\n",
    "    'https://www.turpravda.com/tn/monastir/Skanes_El_Hana-h17555.html',\n",
    "    'https://www.turpravda.com/tn/nabeul/Dessole_Royal_Lido_Resort___Spa-h20035.html',\n",
    "    'https://www.turpravda.com/tn/hammamet/Safa-h27759.html',\n",
    "    'https://www.turpravda.com/tn/port_el_kantaui/Residence_Kantaoui-h26203.html',\n",
    "    'https://www.turpravda.com/tn/nabeul/Dessole_Royal_Lido_Resort___Spa-h20035.html'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b7bff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comments(page_url):\n",
    "    global df_comments\n",
    "    \n",
    "    session = requests.session()\n",
    "    req = session.get(page_url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    for comment in soup.find_all('div', {'class': 'ans_body'}):\n",
    "        mark = comment.find('span', {'class': 'value'})\n",
    "        if mark:\n",
    "            comment_text = comment.find('span', {'class': 'all-text'}).text\n",
    "            mark = float(mark.text[-4:])\n",
    "            df_comments = df_comments.append({'comment': comment_text, \n",
    "                                              'mark': mark,\n",
    "                                              'url': page_url}, ignore_index=True)\n",
    "          \n",
    "    # return all_marks, all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3138ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.DataFrame(columns=['comment', 'mark', 'url'])\n",
    "for page in pages:\n",
    "    get_comments(page) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f60ee2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    85\n",
       "0    72\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments['sentiment'] = df_comments['mark'].apply(lambda x: 1 if x > 5 else 0)\n",
    "df_comments['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3969075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pymorphy2.MorphAnalyzer()\n",
    "ru_words = re.compile(r'\\b[А-Яа-я]+?\\b')\n",
    "sw = stopwords.words('russian')\n",
    "def clean_text(text):\n",
    "    tokens = []\n",
    "    for word in word_tokenize(text):\n",
    "        if ru_words.search(word):\n",
    "            if word not in sw:\n",
    "                tokens.append(m.parse(word.lower())[0].normal_form)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b4cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['tokens'] = df_comments['comment'].apply(clean_text)\n",
    "df_comments['clean_comment'] = df_comments['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7312217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_comments['tokens']\n",
    "y = df_comments['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b550b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = y==1\n",
    "positive_comments = X_train[mask_pos].tolist()\n",
    "negative_comments = X_train[~mask_pos].tolist()\n",
    "\n",
    "positive_corpus = []\n",
    "negative_corpus = []\n",
    "\n",
    "for t in positive_comments:\n",
    "    positive_corpus.extend(t)\n",
    "for t in negative_comments:\n",
    "    negative_corpus.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07acc74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only positive:\n",
      "{'довольно', 'тёплый', 'минус', 'отличный', 'готовить', 'выбор', 'сусс', 'супер', 'менять', 'хотеться', 'але', 'що', 'этаж', 'дуже', 'интересный', 'ваш', 'вкусно', 'ждать', 'возле', 'египет', 'магазин', 'для', 'найти', 'внимание', 'з', 'песок', 'что-то', 'чаевой', 'прекрасный', 'достаточно', 'турция', 'шоу', 'вкусный', 'что', 'аэропорт', 'детский', 'туроператор', 'замечательный', 'взрослый', 'отдельный', 'блюдо', 'красивый', 'любой', 'кормить', 'це', 'сыр', 'обычный', 'кстати', 'главное', 'два', 'разный', 'вопрос', 'такси', 'ми', 'сильно', 'душа', 'креветка', 'дорога', 'написать', 'отношение', 'цена', 'бесплатный', 'конечно', 'готель', 'неделя', 'немного', 'там', 'настроение', 'рядом', 'английский', 'приятный', 'разнообразный', 'покупать', 'буть', 'оставить', 'кто', 'монастир', 'качество', 'тунисский', 'впечатление', 'небольшой', 'приятно', 'убрать', 'центр', 'постель', 'целое', 'чисто', 'язык', 'як'}\n",
      "Only negative:\n",
      "{'ужас', 'он', 'цвет', 'араб', 'понимать', 'к', 'искать', 'вернуться', 'спать', 'комната', 'бутылка', 'кроме', 'тип', 'нечего', 'гость', 'штука', 'конец', 'утром', 'продукт', 'с', 'решить', 'арабский', 'старый', 'выйти', 'нормальный', 'получить', 'кофе', 'прийтись', 'последний', 'как', 'хлорка', 'видимо', 'пытаться', 'после', 'слово', 'посуда', 'пить', 'тарелка', 'какой-то', 'либо', 'поменять', 'особенно', 'гостиница', 'предложить', 'окно', 'увидеть', 'уехать', 'просить', 'туда', 'балкон', 'муха', 'пол', 'приходиться', 'ребята', 'кондиционер', 'жить', 'ужасный', 'дверь', 'ванная', 'оказаться', 'какой', 'глаз', 'уборщица', 'себя', 'стать', 'запах', 'сторона', 'подходить', 'кусок', 'турист', 'женщина', 'попросить', 'народ', 'макароны', 'мыть', 'хотя', 'интернет', 'приходить', 'стакан', 'коридор', 'часто', 'арбуз', 'ездить', 'часть', 'поездка', 'музыка', 'остальной', 'столовая', 'холодильник'}\n"
     ]
    }
   ],
   "source": [
    "cnt_pos = Counter(positive_corpus).most_common(250)\n",
    "cnt_neg = Counter(negative_corpus).most_common(250)\n",
    "\n",
    "set_pos = set(dict(cnt_pos).keys())\n",
    "set_neg = set(dict(cnt_neg).keys())\n",
    "print('Only positive:')\n",
    "print(set_pos-set_neg)\n",
    "print('Only negative:')\n",
    "print(set_neg-set_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286d7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_pos = set_pos - set_neg\n",
    "only_neg = set_neg - set_pos\n",
    "def sentiment(comments):\n",
    "    cnt_pos = 0\n",
    "    cnt_neg = 0\n",
    "    result = []\n",
    "    # comment_tokens = clean_text(comment)\n",
    "    for i, comment in enumerate(comments):\n",
    "        for token in comment:\n",
    "            if token in only_pos:\n",
    "                cnt_pos += 1\n",
    "            elif token in only_neg:\n",
    "                cnt_neg += 1\n",
    "        if cnt_neg > cnt_pos:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "        cnt_pos = 0\n",
    "        cnt_neg = 0\n",
    "    return result\n",
    "\n",
    "y_pred = sentiment(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0adc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_count(y_pred, y_test):\n",
    "    cnt = 0\n",
    "    for p, t in zip(y_pred, y_test):\n",
    "        if p == t:\n",
    "            cnt += 1\n",
    "    return cnt / len(y_pred)\n",
    "\n",
    "accuracy_count(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76d4e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comments = df_comments['clean_comment']\n",
    "y_comments = df_comments['sentiment']\n",
    "X_comments_train, X_comments_test, y_comments_train, y_comments_test = train_test_split(X_comments, y_comments, train_size=.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ad91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train_vec = vec.fit_transform(X_comments_train)\n",
    "X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_vec, y_comments_train)\n",
    "y_preds = knn.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c18ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_count(y_preds, y_comments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55bdda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X_train_vec = vec.fit_transform(X_comments_train)\n",
    "X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X_train_vec, y_comments_train)\n",
    "y_preds = clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d57ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_count(y_preds, y_comments_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ac9a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "X_train_wv = []\n",
    "y_train_wv = []\n",
    "empts = []\n",
    "for i, c in enumerate(X_train):\n",
    "    new_c = []\n",
    "    for word in c:\n",
    "        try:\n",
    "            emb = model.wv[word]\n",
    "            new_c.append(emb)\n",
    "        except:\n",
    "            empts.append(word)\n",
    "    if len(new_c) != 0:\n",
    "        y_train_wv.append(y_train.tolist()[i])\n",
    "        X_train_wv.append(np.array(new_c).mean(axis=0))\n",
    "    new_c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af830df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_wv = []\n",
    "y_test_wv = []\n",
    "empts = []\n",
    "for i, c in enumerate(X_test):\n",
    "    new_c = []\n",
    "    for word in c:\n",
    "        try:\n",
    "            emb = model.wv[word]\n",
    "            new_c.append(emb)\n",
    "        except:\n",
    "            empts.append(word)\n",
    "    if len(new_c) != 0:\n",
    "        y_test_wv.append(y_test.tolist()[i])\n",
    "        X_test_wv.append(np.array(new_c).mean(axis=0))\n",
    "    new_c = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f2ece8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for i in range(1, 50):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i, weights='distance', p=2)\n",
    "    clf.fit(X_train_wv, y_train_wv)\n",
    "    y_preds = clf.predict(X_test_wv)\n",
    "    accs.append(accuracy_count(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "820953af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6129032258064516"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73345bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    vec = TfidfVectorizer(ngram_range=(1, i))\n",
    "    X_train_vec = vec.fit_transform(X_comments_train)\n",
    "    X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=70, max_depth=5)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_preds = clf.predict(X_test_vec)\n",
    "    accs.append(accuracy_count(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8809d259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.8125)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(accs), max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b73aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(10, 100, 10):\n",
    "    vec = TfidfVectorizer(ngram_range=(1, 6))\n",
    "    X_train_vec = vec.fit_transform(X_comments_train)\n",
    "    X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=i, max_depth=5)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_preds = clf.predict(X_test_vec)\n",
    "    accs.append(accuracy_count(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "593c7c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.71875)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(accs), max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be6c9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "accs = []\n",
    "for i in range(1, 5):\n",
    "    '''vec = CountVectorizer(ngram_range=(1, i))\n",
    "    X_train_vec = vec.fit_transform(X_comments_train)\n",
    "    X_test_vec = vec.transform(X_comments_test)'''\n",
    "\n",
    "    vec = TfidfVectorizer(ngram_range=(1, i))\n",
    "    X_train_vec = vec.fit_transform(X_comments_train)\n",
    "    X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "    clf = CatBoostClassifier(iterations=70, max_depth=10, loss_function='Logloss', learning_rate=.1, verbose=False)\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_preds = clf.predict(X_test_vec)\n",
    "    accs.append(accuracy_count(y_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69f9fcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "302b1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7307692307692307 при CountVectorizer\n",
    "# iterations=70, max_depth=10, loss_function='Logloss', learning_rate=.1, verbose=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
