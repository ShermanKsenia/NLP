{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cf8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pymorphy2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from fake_useragent import UserAgent\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a35a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee5184",
   "metadata": {},
   "source": [
    "### 1. Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd67b6",
   "metadata": {},
   "source": [
    "Я выбрала сайт https://www.turpravda.com/tn/top-hotels.html с отзывами на отели Туниса. Оттуда я взяла страницы с отелями, которые оценивались на 9-10, 7, 6 и 1-5 баллов в среднем. На каждой странице максимум 25 отелей. \n",
    "\n",
    "Так как страницы с самими отзывами позволяют просматривать новые отзывы только по нажатию специальной кнопки, пришлось брать только по 10 первых отзывов с каждой страницы, так как я не нашла функционала, с помощью которого можно достать больше отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b7bff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comments(page_url):\n",
    "    global df_comments\n",
    "    \n",
    "    session = requests.session()\n",
    "    req = session.get(page_url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    for comment in soup.find_all('div', {'class': 'ans_body'}):\n",
    "        mark = comment.find('span', {'class': 'value'})\n",
    "        if mark:\n",
    "            comment_text = comment.find('span', {'class': 'all-text'}).text\n",
    "            mark = float(mark.text[-4:])\n",
    "            df_comments = df_comments.append({'comment': comment_text, \n",
    "                                              'mark': mark,\n",
    "                                              'url': page_url}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087f5306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:35<00:00,  2.20s/it]\n",
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n",
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n",
      "100%|██████████| 25/25 [00:54<00:00,  2.19s/it]\n",
      "100%|██████████| 25/25 [00:50<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "df_comments = pd.DataFrame(columns=['comment', 'mark', 'url'])\n",
    "rates = [9, 7, 6, 5, '5&p=2']\n",
    "\n",
    "for i in rates:\n",
    "    page_url = f'https://www.turpravda.com/tn/top-hotels.html?rte%5B%5D={i}'\n",
    "    session = requests.session()\n",
    "    req = session.get(page_url, headers=headers)\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    all_hrefs = soup.find_all('a', {'class': 'hotel-name-title'})\n",
    "    for href in tqdm(all_hrefs):\n",
    "        link = href.get('href')\n",
    "        get_comments('https://www.turpravda.com' + link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffca56c",
   "metadata": {},
   "source": [
    "Таким образом, у меня получилось почти равное количество положительных и отрицательных отзывов. К отрицательным я относила те отзывы, в которых оценка от 1 до 5, включительно. Остальные я относила к положительным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60ee2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    487\n",
       "0    422\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments['sentiment'] = df_comments['mark'].apply(lambda x: 1 if x > 5 else 0)\n",
    "df_comments['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc14771",
   "metadata": {},
   "source": [
    "### 2. Создание словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3969075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pymorphy2.MorphAnalyzer()\n",
    "sw = stopwords.words('russian')\n",
    "def clean_text(text):\n",
    "    tokens = []\n",
    "    for word in word_tokenize(text):\n",
    "        if word.isalpha():\n",
    "            if word not in sw:\n",
    "                tokens.append(m.parse(word.lower())[0].normal_form)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b4cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['tokens'] = df_comments['comment'].apply(clean_text)\n",
    "df_comments['clean_comment'] = df_comments['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7312217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_comments['tokens']\n",
    "y = df_comments['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b550b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = y==1\n",
    "positive_comments = X_train[mask_pos].tolist()\n",
    "negative_comments = X_train[~mask_pos].tolist()\n",
    "\n",
    "positive_corpus = []\n",
    "negative_corpus = []\n",
    "\n",
    "for t in positive_comments:\n",
    "    positive_corpus.extend(t)\n",
    "for t in negative_comments:\n",
    "    negative_corpus.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07acc74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only positive:\n",
      "{'турция', 'неплохой', 'белый', 'сахар', 'быстро', 'ну', 'кухня', 'спасибо', 'отличный', 'внимание', 'интересный', 'английский', 'расположить', 'такси', 'выбрать', 'для', 'зелёный', 'именно', 'танец', 'центр', 'приятный', 'недостаток', 'хаммамет', 'прекрасный', 'разнообразный', 'сладость', 'шоу', 'уровень', 'уходить', 'бесплатно', 'французский', 'народ', 'замечательный', 'супер', 'горка', 'бесплатный', 'ребята', 'вкусно', 'вход', 'линия', 'приветливый', 'всякий', 'обязательно', 'вернуться', 'медина', 'некоторый', 'целое', 'спокойный', 'берег', 'тёплый', 'покупать', 'метр', 'довольный', 'до', 'вполне', 'чисто', 'качество', 'небольшой', 'язык', 'француз', 'дешёвый', 'любой', 'поездка', 'порт', 'достаточно', 'отлично', 'голодный', 'погода', 'новый', 'обслуживание', 'кормить', 'пройти'}\n",
      "Only negative:\n",
      "{'нечего', 'полный', 'шезлонг', 'тип', 'ванная', 'найти', 'остальной', 'музыка', 'принцип', 'приходить', 'грязь', 'друг', 'к', 'стоять', 'рука', 'прийтись', 'увидеть', 'следующий', 'жить', 'должный', 'тарелка', 'столовая', 'муха', 'посуда', 'работник', 'пока', 'автобус', 'бутылка', 'немой', 'часто', 'начать', 'количество', 'лежать', 'араб', 'спать', 'оказаться', 'комната', 'причём', 'соседний', 'выходить', 'пить', 'ужасный', 'дверь', 'кровать', 'оставить', 'попросить', 'стакан', 'занимать', 'сильно', 'думать', 'просить', 'бельё', 'туалет', 'отвратительный', 'дело', 'окно', 'матрас', 'либо', 'приходиться', 'стараться', 'после', 'грязный', 'тур', 'алкоголь', 'вроде', 'он', 'запах', 'сделать', 'последний', 'ужас', 'купаться', 'заплатить'}\n"
     ]
    }
   ],
   "source": [
    "cnt_pos = Counter(positive_corpus).most_common(300)\n",
    "cnt_neg = Counter(negative_corpus).most_common(300)\n",
    "\n",
    "set_pos = set(dict(cnt_pos).keys())\n",
    "set_neg = set(dict(cnt_neg).keys())\n",
    "print('Only positive:')\n",
    "print(set_pos-set_neg)\n",
    "print('Only negative:')\n",
    "print(set_neg-set_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "286d7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_pos = set_pos - set_neg\n",
    "only_neg = set_neg - set_pos\n",
    "def sentiment(comments):\n",
    "    cnt_pos = 0\n",
    "    cnt_neg = 0\n",
    "    result = []\n",
    "    for i, comment in enumerate(comments):\n",
    "        for token in comment:\n",
    "            if token in only_pos:\n",
    "                cnt_pos += 1\n",
    "            elif token in only_neg:\n",
    "                cnt_neg += 1\n",
    "        if cnt_neg > cnt_pos:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "        cnt_pos = 0\n",
    "        cnt_neg = 0\n",
    "    return result\n",
    "\n",
    "y_pred = sentiment(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a0adc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7472527472527473"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_count(y_pred, y_test):\n",
    "    cnt = 0\n",
    "    for p, t in zip(y_pred, y_test):\n",
    "        if p == t:\n",
    "            cnt += 1\n",
    "    return cnt / len(y_pred)\n",
    "\n",
    "accuracy_count(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74d104",
   "metadata": {},
   "source": [
    "Полученный способ позволил достичь accuracy 0.747. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f506a",
   "metadata": {},
   "source": [
    "### Добавление моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5d7a3",
   "metadata": {},
   "source": [
    "С помощью словарей мы обращаем внимание на количество слов, принадлежащих одному или другому классу, однако, возможно важно смотреть не столько на количество всех слов одного класса, сколько на количество определённых слов по отдельности. Поэтому я предлагаю закодировать вектора с помощью CountVectorizer, чтобы обращать внимание на все слова в комментарии, и предсказывать с помощью Logistic Regression, который после обучения сможет поставить коэффициенты на те слова, которые наиболее сильно влияют на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d4e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_comments = df_comments['clean_comment']\n",
    "y_comments = df_comments['sentiment']\n",
    "X_comments_train, X_comments_test, y_comments_train, y_comments_test = train_test_split(X_comments, y_comments, train_size=.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55bdda77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "X_train_vec = vec.fit_transform(X_comments_train)\n",
    "X_test_vec = vec.transform(X_comments_test)\n",
    "\n",
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X_train_vec, y_comments_train)\n",
    "y_preds = clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d57ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_count(y_preds, y_comments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426539b",
   "metadata": {},
   "source": [
    "Качество улучшилось на 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b464b0c",
   "metadata": {},
   "source": [
    "Аналогичный результат получается при использовании баесовской модели MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78083cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626373626373627"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_comments_train)\n",
    "y_preds = clf.predict(X_test_vec)\n",
    "accuracy_count(y_preds, y_comments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f29fbc",
   "metadata": {},
   "source": [
    "Также я решила попробовать обучить модель определять тональность комментария на основе эмбеддинга самого комментария. Для этого я взяла обученную модель Word2Vec, подстроила данные под входные данные для модели и каждый отзыв представила как средний вектор всех представлений слов. После я обучила модель Logistic Regression предсказывать тональность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af232f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 727/727 [00:29<00:00, 24.42it/s]\n",
      "100%|██████████| 182/182 [00:09<00:00, 18.48it/s]\n"
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-ruscorpora-300')\n",
    "\n",
    "# Перевод pos-тэгов pymorphy в pos-тэги модели (причастия и деепричастия я считала глаголами)\n",
    "pos_model = {'NOUN': 'NOUN', 'VERB': 'VERB', 'ADJF': 'ADJ', \n",
    "            'ADJS': 'ADJ', 'PRTS': 'VERB', 'COMP': 'ADJ',\n",
    "            'ADVB': 'ADV', 'INFN': 'VERB', 'NPRO': 'PRON', \n",
    "            'PREP':'ADP', 'PRED': 'ADV', 'PRTF': 'VERB',\n",
    "            'NUMR': 'NUM', 'CONJ': 'CCONJ', 'INTJ': 'INTJ', \n",
    "            'PRCL': 'PART', 'GRND': 'VERB'}\n",
    "\n",
    "# создание датасета для модели\n",
    "# к каждому слову в конце добавляется тэг части речи\n",
    "X_train_wv = []\n",
    "for comment in tqdm(X_train):\n",
    "    new_comment = []\n",
    "    for word in comment:\n",
    "        pos = m.parse(word)[0].tag.POS\n",
    "        if pos:\n",
    "            new_comment.append(f'{word}_{pos_model[pos]}')\n",
    "    X_train_wv.append(new_comment)\n",
    "\n",
    "X_test_wv = []\n",
    "for comment in tqdm(X_test):\n",
    "    new_comment = []\n",
    "    for word in comment:\n",
    "        pos = m.parse(word)[0].tag.POS\n",
    "        if pos:\n",
    "            new_comment.append(f'{word}_{pos_model[pos]}')\n",
    "    X_test_wv.append(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1f53bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "empts = []  # список слов, которых нет в словаре модели (с повторениями)\n",
    "all_words = 0  # счётчик общего количества слов (с повторениями)\n",
    "\n",
    "# создание вектора отзыва\n",
    "# случаи, когда ни одно слово не входило в словарь, исключались\n",
    "X_train_emb = []\n",
    "y_train_emb = []\n",
    "for comment, y in zip(X_train_wv, y_train):\n",
    "    comment_emb = []\n",
    "    all_words += len(comment)\n",
    "    for word in comment:\n",
    "        try:\n",
    "            comment_emb.append(model[word])\n",
    "        except:\n",
    "            empts.append(word)\n",
    "    if comment_emb != []:\n",
    "        X_train_emb.append(np.mean(comment_emb, axis=0))\n",
    "        y_train_emb.append(y)\n",
    "\n",
    "X_test_emb = []\n",
    "y_test_emb = []\n",
    "for comment, y in zip(X_test_wv, y_test):\n",
    "    comment_emb = []\n",
    "    all_words += len(comment)\n",
    "    for word in comment:\n",
    "        try:\n",
    "            comment_emb.append(model[word])\n",
    "        except:\n",
    "            empts.append(word)\n",
    "    if comment_emb != []:\n",
    "        X_test_emb.append(np.mean(comment_emb, axis=0))\n",
    "        y_test_emb.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa43bd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7833333333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X_train_emb, y_train_emb)\n",
    "y_preds = clf.predict(X_test_emb)\n",
    "accuracy_count(y_preds, y_test_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a710e3b",
   "metadata": {},
   "source": [
    "Таким образом, accuracy улучшилась на 4 процента по сравнению с изначальным предсказанием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7f7a7a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова не из словаря: 42558\n",
      "Слова в словаре: 189202\n"
     ]
    }
   ],
   "source": [
    "print('Слова не из словаря:', len(empts))\n",
    "print('Слова в словаре:', all_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
